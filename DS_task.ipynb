{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In what follows, I create functions which predict ID of a retailer's product with a given name, retailer's origin and its \n",
    "brand name (feature set) based on a products database which associates product's features with its unique ID. \n",
    "\n",
    "First approach uses machine-learning (ML) algorithm which exploits feature set of a product and finds the best match for a \n",
    "retailer's product based on a specified rule. Specifically, I use features of a product such as its name \"bag of characters\" and the name's length, and the origin of its retailer. I hypothesize that two names with similar \"bag of characters\" are likely to share the same ID. Moreover, I impose penalty on the product's name with which I compare a retailer's product. Last factor in my model is a dummy variable which equals 1 if retailers of two products share common origin. To compare two names, I create a linear function (which can be easily extended to any other shape) with arguments corresponding to product features and estimate its parameters in a training sample. Finally, I estimate accuracy of my model by validation sample approach. Note that this can be also done, say, by K-fold cross-validation, yet the final results shouldn't be considerably different from each other in this case, so I exclude this estimation to save computational time.\n",
    "\n",
    "Second approach exploits built-in Python function \"get_close_matches\" from \"difflib\" library which finds the best match of a \n",
    "word among the list of other words. In this case, to predict a retailer product's ID given product database I run through the \n",
    "poducts database and search for a product's name which matches the name of the retailer's  product in the best way and assign its ID to the retailer product. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import difflib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload dataset and convert dataframe to list\n",
    "df = pd.read_csv(r'train_lenses_ds_task.csv', encoding = 'utf8')\n",
    "Products_list = [df.columns.values.tolist()] + df.values.tolist()\n",
    "Products_list = Products_list[1:len(Products_list)][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract key features of a product: its name and retailer's origin  \n",
    "product_id = [new[0] for new in Products_list ]\n",
    "origin = [new[2] for new in Products_list ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove redundant spaces in products names to consider the names as \"bag of characters\"\n",
    "NameSplit = []\n",
    "for new in Products_list:\n",
    "    newlist = list(new[1])\n",
    "    while newlist.count(' ') > 0:\n",
    "        newlist.remove(' ')\n",
    "    NameSplit.append(newlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge product_id and product name\n",
    "products =[]\n",
    "for i in range(len(product_id)):\n",
    "    products.append([product_id[i], NameSplit[i], origin[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Approach (via Machine Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product ID is found in different countries!\n"
     ]
    }
   ],
   "source": [
    "# Check whether a product ID can be supplied by foreign retailers\n",
    "found = 0\n",
    "for i in range(len(products)):\n",
    "    for j in range(i,len(products)):\n",
    "        if products[i][2] != products[j][2] and products[i][0] == products[j][0]:\n",
    "            found = 1\n",
    "            break\n",
    "    if found == 1:\n",
    "        print(\"Product ID is found in different countries!\")\n",
    "        break \n",
    "    if i == len(products) - 1:\n",
    "        print(\"Each product ID is domestic!\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model    \n",
    "def train(trainSam,lam1,lam2,lam3):\n",
    "    predictedID = []\n",
    "    for obsDraw in trainSam:\n",
    "        trainRem = trainSam.copy()\n",
    "        trainRem.remove(obsDraw)\n",
    "        score = []\n",
    "        for obsRem in trainRem:\n",
    "        # Compare countries\n",
    "            if obsDraw[2] == obsRem[2]:\n",
    "                countryDummy = 1\n",
    "            else:\n",
    "                countryDummy = 0\n",
    "            # Create list of matched characters of product names\n",
    "            matchedChars = list(set(obsDraw[1]) & set(obsRem[1])) \n",
    "            # Compute total number of matched characters\n",
    "            matchedCharsNum = 0  \n",
    "            for newchar in matchedChars:\n",
    "                matchedCharsNum += obsDraw[1].count(newchar)\n",
    "            # Penalize lengthy words with which we compare    \n",
    "            nameLength = len(obsRem[1])\n",
    "            # Define linear score-function with arguments: number of matched characters, country of retailer and the product name's length  \n",
    "            score.append(lam1*matchedCharsNum + lam2*countryDummy + lam3*nameLength) \n",
    "        # Find first entrance of max score in candidate list   \n",
    "        indMax = score.index(max(score))  \n",
    "        # Retrieve all product IDs in remaining sample\n",
    "        IDpred = [x[0] for x in trainRem][indMax] \n",
    "        # augment set of predicted IDs\n",
    "        predictedID.append([IDpred,obsDraw[1]])\n",
    "    # Compute number of correctly predicted IDs\n",
    "    numPred = 0\n",
    "    for i in range(len(predictedID)):\n",
    "        if predictedID[i][0] == trainSam[i][0]:\n",
    "            numPred += 1\n",
    "    # Return score\n",
    "    return(numPred/len(trainSam)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the model's score on test sample\n",
    "def validate(trainSam, testSam, lam1, lam2, lam3):\n",
    "    predictedID = []\n",
    "    for obsTest in testSam:\n",
    "        score = []\n",
    "        for obsTrain in trainSam:\n",
    "            # Compare countries\n",
    "            if obsTrain[2] == obsTest[2]:\n",
    "                countryDummy = 1\n",
    "            else:\n",
    "                countryDummy = 0\n",
    "            # Create list of matched characters of product names\n",
    "            matchedChars = list(set(obsTest[1]) & set(obsTrain[1])) \n",
    "            # Compute total number of matched characters\n",
    "            matchedCharsNum = 0  \n",
    "            for newchar in matchedChars:\n",
    "                matchedCharsNum += obsTest[1].count(newchar)\n",
    "            nameLength = len(obsTrain[1])\n",
    "            # Compute linear score-function given estimated parameters lam1,lam2,lam3 from train sample  \n",
    "            score.append(lam1*matchedCharsNum + lam2*countryDummy + lam3*nameLength) \n",
    "        # Find first entrance of max score in candidate list   \n",
    "        indMax = score.index(max(score))  \n",
    "        # Retrieve all product IDs\n",
    "        IDpred = [x[0] for x in trainSam][indMax] \n",
    "        # augment set of predicted IDs\n",
    "        predictedID.append([IDpred,obsTest[1]])\n",
    "    # Find distinct IDs in training sample which are present in test sample    \n",
    "    matchedIDs = list(set([x[0] for x in testSam] ) & set([x[0] for x in trainSam]))\n",
    "    # Total number of IDs in test sample which can be matched with IDs in train sample\n",
    "    matchedIDsNum = 0\n",
    "    for newID in matchedIDs:\n",
    "        matchedIDsNum += [new[0] for new in testSam].count(newID)\n",
    "    # Compute number of correctly predicted IDs\n",
    "    corIDsPred = 0\n",
    "    for i in range(len(predictedID)):\n",
    "        if predictedID[i][0] == testSam[i][0]:\n",
    "            corIDsPred += 1\n",
    "    # Return score\n",
    "    score = corIDsPred/matchedIDsNum\n",
    "    return(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6957746478873239\n"
     ]
    }
   ],
   "source": [
    "# Specify share of data to be used in test sample\n",
    "test_size = 0.4\n",
    "datatrain, datatest = train_test_split(products, test_size = test_size)\n",
    " \n",
    "# Train model\n",
    "scores = []\n",
    "trainResults = []\n",
    "# Next, I guess some grid values of model parameters. In particular, I use only two ad-hoc values for train sample size of 0.9. \n",
    "# However, there's a clear trade-off between the estimation time and the grid fineness. \n",
    " \n",
    "# Run through grid of parameter lam1 \n",
    "for lam1 in (10,16):\n",
    "   # --//-- of parameter lam2\n",
    "    for lam2 in (0,2):\n",
    "# --//-- of parameter lam3\n",
    "        for lam3 in (-2,-0.5):\n",
    "            score = train(datatrain,lam1,lam2,lam3)\n",
    "            trainResults.append([lam1,lam2,lam3,score])\n",
    "            scores.append(score)\n",
    "# Find index of optimal parameters lam1,lam2,lam3             \n",
    "maxScoreInd = scores.index(max(scores))\n",
    "hatLam1 = [x[0] for x in trainResults][maxScoreInd]\n",
    "hatLam2 = [x[1] for x in trainResults][maxScoreInd]\n",
    "hatLam3 = [x[2] for x in trainResults][maxScoreInd]\n",
    " \n",
    "# Given optimal model parameters lam1,lam2,lam3 validate the model and find the model's score             \n",
    "testScore = validate(datatrain, datatest,hatLam1,hatLam2,hatLam3)\n",
    "print(testScore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Second Approach (via Text Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define score via built-in function get_close_matches\n",
    "def scorer(trainSam, testSam):\n",
    "    predictedID = []\n",
    "    for obsTest in testSam:\n",
    "        # find the best matched name in training sample for selected item's name in test sample\n",
    "        bestMatch = difflib.get_close_matches(obsTest[1], [x[1] for x in trainSam])\n",
    "        # If the best match wasn't found ignore this observation further\n",
    "        if bestMatch == []:\n",
    "            indPred = []\n",
    "            predictedID.append([indPred,obsTest[1]])\n",
    "        # If the best match was found assign its ID to the selected observation    \n",
    "        else:\n",
    "            indMatched = [x[1] for x in trainSam].index(bestMatch[0])  # First entrance of matched item\n",
    "            indPred = trainSam[indMatched][0]\n",
    "            predictedID.append([indPred,obsTest[1]])\n",
    "    # Find distinct IDs in training sample found in test sample    \n",
    "    matchedIDs = list(set([x[0] for x in testSam] ) & set([x[0] for x in trainSam]))\n",
    "    # Total number of all such IDs in test sample \n",
    "    matchedIDsNum = 0\n",
    "    for newID in matchedIDs:\n",
    "        matchedIDsNum += [new[0] for new in testSam].count(newID)\n",
    "    # Compute total number of correctly predicted IDs\n",
    "    corIDsPred = 0\n",
    "    for i in range(len(predictedID)):\n",
    "        if predictedID[i][0] == testSam[i][0]:\n",
    "            corIDsPred += 1\n",
    "    # Return score\n",
    "    score = corIDsPred/matchedIDsNum\n",
    "    return(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8704225352112676\n"
     ]
    }
   ],
   "source": [
    "# CV procedure \n",
    "test_size = 0.1\n",
    "datatrain, datatest = train_test_split(products, test_size = test_size)\n",
    "print(scorer(datatrain, datatest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
